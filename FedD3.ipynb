{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d34e1c-1f56-492c-95d8-6ef205c8ea07",
   "metadata": {},
   "source": [
    "##### Check python version (required python version: 3.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e0ef1-22a4-40d2-a773-9874ef81f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b0393-29d4-4ad5-9d18-e8819a216a85",
   "metadata": {},
   "source": [
    "### Package installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895eea2-f634-47dc-a427-28bd19c1a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy~=1.21.5 scipy~=1.7.0 Pillow~=8.2.0 torch~=1.8.1 torchvision~=0.9.1 matplotlib~=3.4.2 opencv-python~=4.5.3.56\n",
    "!pip install scikit-learn~=0.24.2 colorama~=0.4.4 jax>=0.3.7 jaxlib>=0.3.7 neural-tangents~=0.6.0 pykeops~=2.1 tqdm~=4.61.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eccb6c-115b-421a-91c3-ec808ec104e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136cc51-9417-42cb-9d84-c1ba9cd2afd5",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0b8d6-b0bb-4184-8795-f12f248ceee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import yaml\n",
    "import json\n",
    "import pickle\n",
    "from json import JSONEncoder\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532e364-4b5b-41cd-b8ed-382bcf24fe5e",
   "metadata": {},
   "source": [
    "#### Function to load/download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b19d9-a47d-4b35-ad18-c3da1fb2aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name, root='./data', download=True, save_pre_data=True):\n",
    "\n",
    "    data_dict = ['MNIST', 'EMNIST', 'FashionMNIST',\n",
    "                 'CelebA', 'CIFAR10', 'QMNIST', 'SVHN', 'CIFAR100']\n",
    "    assert name in data_dict, \"The dataset is not present\"\n",
    "\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "\n",
    "    file_dir = root+'/prepared/'\n",
    "    test_data_file = file_dir + name + '_test.pt'\n",
    "    train_data_file = file_dir + name + '_train.pt'\n",
    "    test_targets_file = file_dir + name + '_test_label.pt'\n",
    "    train_targets_file = file_dir + name + '_train_label.pt'\n",
    "\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs(file_dir, exist_ok=True)\n",
    "\n",
    "    all_file_there = os.path.exists(train_data_file) and os.path.exists(\n",
    "        test_data_file) and os.path.exists(train_targets_file) and os.path.exists(test_targets_file)\n",
    "\n",
    "    if save_pre_data or not all_file_there:\n",
    "\n",
    "        if name == 'MNIST':\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "            trainset = torchvision.datasets.MNIST(\n",
    "                root=root, train=True, download=download, transform=transform)\n",
    "            testset = torchvision.datasets.MNIST(\n",
    "                root=root, train=False, download=download, transform=transform)\n",
    "\n",
    "        elif name == 'EMNIST':\n",
    "            # byclass, bymerge, balanced, letters, digits, mnist\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "            trainset = torchvision.datasets.EMNIST(\n",
    "                root=root, train=True, split='letters', download=download, transform=transform)\n",
    "            testset = torchvision.datasets.EMNIST(\n",
    "                root=root, train=False, split='letters', download=download, transform=transform)\n",
    "\n",
    "        elif name == 'FashionMNIST':\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "            trainset = torchvision.datasets.FashionMNIST(\n",
    "                root=root, train=True, download=download, transform=transform)\n",
    "            testset = torchvision.datasets.FashionMNIST(\n",
    "                root=root, train=False, download=download, transform=transform)\n",
    "\n",
    "        elif name == 'CelebA':\n",
    "            # Could not loaded possibly for google drive break downs, try again at week days\n",
    "            target_transform = transforms.Compose([transforms.ToTensor()])\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "            trainset = torchvision.datasets.CelebA(\n",
    "                root=root, split='train', target_type=list, download=download, transform=transform, target_transform=target_transform)\n",
    "            testset = torchvision.datasets.CelebA(\n",
    "                root=root, split='test', target_type=list, download=download, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        elif name == 'CIFAR10':\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "            trainset = torchvision.datasets.CIFAR10(\n",
    "                root=root, train=True, download=download, transform=transform)\n",
    "            testset = torchvision.datasets.CIFAR10(\n",
    "                root=root, train=False, download=download, transform=transform)\n",
    "            trainset.targets = torch.Tensor(trainset.targets)\n",
    "            testset.targets = torch.Tensor(testset.targets)\n",
    "\n",
    "        elif name == 'CIFAR100':\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "            trainset = torchvision.datasets.CIFAR100(\n",
    "                root=root, train=True, transform=transform, download=True)\n",
    "            testset = torchvision.datasets.CIFAR100(\n",
    "                root=root, train=False, transform=transform, download=True)\n",
    "            trainset.targets = torch.Tensor(trainset.targets)\n",
    "            testset.targets = torch.Tensor(testset.targets)\n",
    "\n",
    "        elif name == 'QMNIST':\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "            trainset = torchvision.datasets.QMNIST(\n",
    "                root=root, what='train', compat=True, download=download, transform=transform)\n",
    "            testset = torchvision.datasets.QMNIST(\n",
    "                root=root, what='test', compat=True, download=download, transform=transform)\n",
    "\n",
    "        elif name == 'SVHN':\n",
    "\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(\n",
    "                (0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614))])\n",
    "            trainset = torchvision.datasets.SVHN(\n",
    "                root=root, split='train', download=download, transform=transform)\n",
    "            testset = torchvision.datasets.SVHN(\n",
    "                root=root, split='test', download=download, transform=transform)\n",
    "            trainset.targets = torch.Tensor(trainset.labels)\n",
    "            testset.targets = torch.Tensor(testset.labels)\n",
    "\n",
    "        end = len(trainset)-1\n",
    "        copy_burden = 50\n",
    "        for i, x in tqdm(enumerate(trainset)):\n",
    "            if i == end:\n",
    "                temp = torch.cat((temp, torch.unsqueeze(x[0], 0)))\n",
    "                train_data = torch.cat((train_data, temp))\n",
    "                train_targets = trainset.targets\n",
    "\n",
    "            elif i % copy_burden != 0:\n",
    "                temp = torch.cat((temp, torch.unsqueeze(x[0], 0)))\n",
    "\n",
    "            elif i/copy_burden != 0 and i/copy_burden != 1:\n",
    "                train_data = torch.cat((train_data, temp))\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "            elif i/copy_burden == 0:\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "            else:\n",
    "                train_data = temp\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "        end = len(testset)-1\n",
    "        for i, x in tqdm(enumerate(testset)):\n",
    "            if i == end:\n",
    "                temp = torch.cat((temp, torch.unsqueeze(x[0], 0)))\n",
    "                test_data = torch.cat((test_data, temp))\n",
    "                test_targets = testset.targets\n",
    "\n",
    "            elif i % copy_burden != 0:\n",
    "                temp = torch.cat((temp, torch.unsqueeze(x[0], 0)))\n",
    "\n",
    "            elif i/copy_burden != 0 and i/copy_burden != 1:\n",
    "                test_data = torch.cat((test_data, temp))\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "            elif i/copy_burden == 0:\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "            else:\n",
    "                test_data = temp\n",
    "                temp = torch.unsqueeze(x[0], 0)\n",
    "\n",
    "        torch.save(train_data, train_data_file)\n",
    "        torch.save(test_data, test_data_file)\n",
    "        torch.save(train_targets, train_targets_file)\n",
    "        torch.save(test_targets, test_targets_file)\n",
    "\n",
    "    elif all_file_there and not save_pre_data:\n",
    "        train_data = torch.load(train_data_file)\n",
    "        test_data = torch.load(test_data_file)\n",
    "        train_targets = torch.load(train_targets_file)\n",
    "        test_targets = torch.load(test_targets_file)\n",
    "\n",
    "    # Set len_classes\n",
    "    len_classes_dict = {\n",
    "        'MNIST': 10,\n",
    "        # ByClass: 62. ByMerge: 814,255 47.Digits: 280,000 10.Letters: 145,600 26.MNIST: 70,000 10.\n",
    "        'EMNIST': 27,\n",
    "        'FashionMNIST': 10,\n",
    "        'CelebA': 0,\n",
    "        'CIFAR10': 10,\n",
    "        'CIFAR100': 100,\n",
    "        'QMNIST': 10,\n",
    "        'SVHN': 10\n",
    "    }\n",
    "\n",
    "    len_classes = len_classes_dict[name]\n",
    "\n",
    "    return len_classes, train_data, train_targets, test_data, test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78e462-8f51-4a02-b6b8-72a5099447e2",
   "metadata": {},
   "source": [
    "### Divide data into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2670f7f-6607-482a-a688-721a85453e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(num_client=1, num_local_class=10, dataset_name='emnist', i_seed=0):\n",
    "    torch.manual_seed(i_seed)\n",
    "\n",
    "    num_classes, train_data, train_targets, test_data, test_targets = load_data(\n",
    "        dataset_name, download=True, save_pre_data=False)\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if num_local_class == -1:\n",
    "        num_local_class = num_classes\n",
    "    assert 0 < num_local_class <= num_classes, \"number of local class should smaller than global number of class\"\n",
    "\n",
    "    trainset_config = {'users': [],\n",
    "                       'user_data': {},\n",
    "                       'num_samples': []}\n",
    "    config_division = {}  # Count of the classes for division\n",
    "    config_class = {}  # Configuration of class distribution in clients\n",
    "    # Configuration of data indexes for each class : Config_data[cls] = [0, []] | pointer and indexes\n",
    "    config_data = {}\n",
    "\n",
    "    for i in range(num_client):\n",
    "        config_class['f_{0:05d}'.format(i)] = []\n",
    "        for j in range(num_local_class):\n",
    "            cls = (i+j) % num_classes\n",
    "            if cls not in config_division:\n",
    "                config_division[cls] = 1\n",
    "                config_data[cls] = [0, []]\n",
    "\n",
    "            else:\n",
    "                config_division[cls] += 1\n",
    "            config_class['f_{0:05d}'.format(i)].append(cls)\n",
    "\n",
    "    for cls in config_division.keys():\n",
    "        indexes = torch.nonzero(train_targets == cls)\n",
    "        num_datapoint = indexes.shape[0]\n",
    "        indexes = indexes[torch.randperm(num_datapoint)]\n",
    "        num_partition = num_datapoint // config_division[cls]\n",
    "        for i_partition in range(config_division[cls]):\n",
    "            if i_partition == config_division[cls] - 1:\n",
    "                config_data[cls][1].append(\n",
    "                    indexes[i_partition * num_partition:])\n",
    "            else:\n",
    "                config_data[cls][1].append(\n",
    "                    indexes[i_partition * num_partition: (i_partition + 1) * num_partition])\n",
    "\n",
    "    for user in tqdm(config_class.keys()):\n",
    "        user_data_indexes = torch.tensor([])\n",
    "        for cls in config_class[user]:\n",
    "            user_data_index = config_data[cls][1][config_data[cls][0]]\n",
    "            user_data_indexes = torch.cat((user_data_indexes, user_data_index))\n",
    "            config_data[cls][0] += 1\n",
    "            # print(len(user_data_indexes))\n",
    "        user_data = train_data[user_data_indexes.tolist()]\n",
    "        user_targets = train_targets[user_data_indexes.tolist()]\n",
    "        trainset_config['users'].append(user)\n",
    "        trainset_config['user_data'][user] = {\n",
    "            'x': user_data, 'y': user_targets}\n",
    "        trainset_config['num_samples'] = len(user_data)\n",
    "        # print(trainset_config['user_data'][user].shape)\n",
    "\n",
    "    test_iid_data = {'x': None, 'y': None}\n",
    "    test_iid_data['x'] = test_data\n",
    "    test_iid_data['y'] = test_targets\n",
    "\n",
    "    return trainset_config, test_iid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a4614-65c3-4640-a685-c336464e7666",
   "metadata": {},
   "source": [
    "### KIP Distill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70802a4b-2d8f-4359-8da5-0e25a85877b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import jax\n",
    "from tqdm import tqdm\n",
    "from neural_tangents import stax\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.config import config\n",
    "from jax import numpy as jnp\n",
    "from jax import scipy as sp\n",
    "\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "\n",
    "def one_hot(x,\n",
    "            num_classes,\n",
    "            center=True,\n",
    "            dtype=np.float32):\n",
    "    assert len(x.shape) == 1\n",
    "    one_hot_vectors = np.array(x[:, None] == np.arange(num_classes), dtype)\n",
    "    if center:\n",
    "        one_hot_vectors = one_hot_vectors - 1. / num_classes\n",
    "    return one_hot_vectors\n",
    "\n",
    "\n",
    "def get_normalization_data(arr):\n",
    "    channel_means = np.mean(arr, axis=(0, 1, 2))\n",
    "    channel_stds = np.std(arr, axis=(0, 1, 2))\n",
    "    return channel_means, channel_stds\n",
    "\n",
    "\n",
    "def normalize(arr, mean, std):\n",
    "    return (arr - mean) / std\n",
    "\n",
    "\n",
    "def FullyConnectedNetwork(\n",
    "        depth,\n",
    "        width,\n",
    "        W_std=np.sqrt(2),\n",
    "        b_std=0.1,\n",
    "        num_classes=10,\n",
    "        parameterization='ntk',\n",
    "        activation='relu'):\n",
    "    activation_fn = stax.Relu()\n",
    "    dense = functools.partial(\n",
    "        stax.Dense, W_std=W_std, b_std=b_std, parameterization=parameterization)\n",
    "\n",
    "    layers = [stax.Flatten()]\n",
    "    for _ in range(depth):\n",
    "        layers += [dense(width), activation_fn]\n",
    "    layers += [stax.Dense(num_classes, W_std=W_std, b_std=b_std,\n",
    "                          parameterization=parameterization)]\n",
    "\n",
    "    return stax.serial(*layers)\n",
    "\n",
    "\n",
    "def get_kernel_fn(architecture, depth, width, parameterization):\n",
    "    if architecture == 'FC':\n",
    "        return FullyConnectedNetwork(depth=depth, width=width, parameterization=parameterization)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Unrecognized architecture {architecture}')\n",
    "\n",
    "\n",
    "def class_balanced_sample(sample_size: int,\n",
    "                          labels: np.ndarray,\n",
    "                          *arrays: np.ndarray, **kwargs: int):\n",
    "\n",
    "    if labels.ndim != 1:\n",
    "        raise ValueError(f'Labels should be one-dimensional, got shape {labels.shape}')\n",
    "    n = len(labels)\n",
    "    if not all([n == len(arr) for arr in arrays[1:]]):\n",
    "        raise ValueError(\n",
    "            f'All arrays to be subsampled should have the same length. Got lengths {[len(arr) for arr in arrays]}')\n",
    "    classes = np.unique(labels)\n",
    "    n_classes = len(classes)\n",
    "    n_per_class, remainder = divmod(sample_size, n_classes)\n",
    "\n",
    "    if remainder != 0:\n",
    "        raise ValueError(\n",
    "            f'Number of classes {n_classes} in labels must divide sample size {sample_size}.'\n",
    "        )\n",
    "    if kwargs.get('seed') is not None:\n",
    "        np.random.seed(kwargs['seed'])\n",
    "    inds = np.concatenate([\n",
    "        np.random.choice(np.where(labels == c)[0], n_per_class, replace=False)\n",
    "        for c in classes\n",
    "    ])\n",
    "\n",
    "    return (inds, labels[inds].copy()) + tuple(\n",
    "        [arr[inds].copy() for arr in arrays])\n",
    "\n",
    "\n",
    "def make_loss_acc_fn(kernel_fn):\n",
    "    LEARN_LABELS = False\n",
    "\n",
    "    @jax.jit\n",
    "    def loss_acc_fn(x_support, y_support, x_target, y_target, reg=1e-6):\n",
    "        y_support = jax.lax.cond(LEARN_LABELS, lambda y: y, jax.lax.stop_gradient, y_support)\n",
    "        k_ss = kernel_fn(x_support, x_support)\n",
    "        k_ts = kernel_fn(x_target, x_support)\n",
    "        k_ss_reg = (k_ss + jnp.abs(reg) * jnp.trace(k_ss) * jnp.eye(k_ss.shape[0]) / k_ss.shape[0])\n",
    "        pred = jnp.dot(k_ts, sp.linalg.solve(k_ss_reg, y_support, sym_pos=True))\n",
    "        mse_loss = 0.5 * jnp.mean((pred - y_target) ** 2)\n",
    "        acc = jnp.mean(jnp.argmax(pred, axis=1) == jnp.argmax(y_target, axis=1))\n",
    "        return mse_loss, acc\n",
    "\n",
    "    return loss_acc_fn\n",
    "\n",
    "\n",
    "def get_update_functions(init_params, kernel_fn, lr):\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(init_params)\n",
    "\n",
    "    def make_loss_acc_fn(kernel_fn):\n",
    "        LEARN_LABELS = False\n",
    "\n",
    "        @jax.jit\n",
    "        def loss_acc_fn(x_support, y_support, x_target, y_target, reg=1e-6):\n",
    "            y_support = jax.lax.cond(LEARN_LABELS, lambda y: y, jax.lax.stop_gradient, y_support)\n",
    "            k_ss = kernel_fn(x_support, x_support)\n",
    "            k_ts = kernel_fn(x_target, x_support)\n",
    "\n",
    "            # H(X)\n",
    "            k_ss_reg = (k_ss + jnp.abs(reg) * jnp.trace(k_ss) * jnp.eye(k_ss.shape[0]) / k_ss.shape[0])\n",
    "            pred = jnp.dot(k_ts, sp.linalg.solve(k_ss_reg, y_support, sym_pos=True))\n",
    "            mse_loss = 0.5 * jnp.mean((pred - y_target) ** 2)\n",
    "\n",
    "            acc = jnp.mean(jnp.argmax(pred, axis=1) == jnp.argmax(y_target, axis=1))\n",
    "            return mse_loss, acc\n",
    "\n",
    "        return loss_acc_fn\n",
    "\n",
    "    loss_acc_fn = make_loss_acc_fn(kernel_fn)\n",
    "    value_and_grad = jax.value_and_grad(lambda params, x_target, y_target: loss_acc_fn(params['x'], params['y'], x_target, y_target), has_aux=True)\n",
    "\n",
    "    @jax.jit\n",
    "    def update_fn(step, opt_state, params, x_target, y_target):\n",
    "        (loss, acc), dparams = value_and_grad(params, x_target, y_target)\n",
    "        return opt_update(step, dparams, opt_state), (loss, acc)\n",
    "\n",
    "    return opt_state, get_params, update_fn\n",
    "\n",
    "# The main function of KIP-instance for local dataset distillation.\n",
    "def distill_kip_unit(x_train_raw,\n",
    "                     y_train_raw,\n",
    "                     num_dd_epoch,\n",
    "                     seed,\n",
    "                     k,\n",
    "                     lr,\n",
    "                     threshold,\n",
    "                     target_sample_size,\n",
    "                     kernel_model,\n",
    "                     depth,\n",
    "                     width):\n",
    "\n",
    "    _, _, kernel_fn = get_kernel_fn(kernel_model, depth, width, 'ntk')\n",
    "    KERNEL_FN = jax.jit(functools.partial(kernel_fn, get='ntk'))\n",
    "\n",
    "    channel_means, channel_stds = get_normalization_data(x_train_raw)\n",
    "    x_train = normalize(x_train_raw, channel_means, channel_stds)\n",
    "    y_train = one_hot(y_train_raw, 10)\n",
    "\n",
    "    _, _, x_init_raw, y_init = class_balanced_sample(k, y_train_raw, x_train_raw, y_train, seed=seed)\n",
    "    x_init = normalize(x_init_raw, channel_means, channel_stds)\n",
    "    params_init = {'x': x_init, 'y': y_init}\n",
    "\n",
    "    opt_state, get_params, update_fn = get_update_functions(params_init, KERNEL_FN, lr)\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    pbar = tqdm(range(1, num_dd_epoch + 1))\n",
    "    for i in pbar:\n",
    "        # full batch gradient descent\n",
    "        _, _, x_target_batch, y_target_batch = class_balanced_sample(target_sample_size, y_train_raw, x_train, y_train)\n",
    "        opt_state, aux = update_fn(i, opt_state, params, x_target_batch, y_target_batch)\n",
    "        train_loss, train_acc = aux\n",
    "        params = get_params(opt_state)\n",
    "        pbar.set_description('Step: %d ' % i + '|Train Loss: %.4f ' % train_loss + '|Train Acc: %.4f ' % train_acc)\n",
    "\n",
    "        if train_acc > threshold:\n",
    "            print(\"converge at loop \", i)\n",
    "            break\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef3592-b15b-4e63-a30f-18e0b9378670",
   "metadata": {},
   "source": [
    "### Initializing models with parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364b5a7-4560-4a92-9889-890895de60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We provide the models, which might be used in the experiments on FedD3, as follows:\n",
    "    - AlexNet model customized for CIFAR-10 (AlexCifarNet) with 1756426 parameters\n",
    "    - LeNet model customized for MNIST with 61706 parameters\n",
    "    - Further ResNet models\n",
    "    - Further Vgg models\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# AlexNet model customized for CIFAR-10 with 1756426 parameters\n",
    "class AlexCifarNet(nn.Module):\n",
    "    supported_dims = {32}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexCifarNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.LocalResponseNorm(4, alpha=0.001 / 9.0, beta=0.75, k=1),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(4, alpha=0.001 / 9.0, beta=0.75, k=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(384, 192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(192, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), 4096)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# LeNet model customized for MNIST with 61706 parameters\n",
    "class LeNet(nn.Module):\n",
    "    supported_dims = {28}\n",
    "\n",
    "    def __init__(self, num_classes=10, in_channels=1):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x), inplace=True)  # 6 x 28 x 28\n",
    "        out = F.max_pool2d(out, 2)  # 6 x 14 x 14\n",
    "        out = F.relu(self.conv2(out), inplace=True)  # 16 x 7 x 7\n",
    "        out = F.max_pool2d(out, 2)   # 16 x 5 x 5\n",
    "        out = out.view(out.size(0), -1)  # 16 x 5 x 5\n",
    "        out = F.relu(self.fc1(out), inplace=True)\n",
    "        out = F.relu(self.fc2(out), inplace=True)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Further ResNet models\n",
    "def generate_resnet(num_classes=10, in_channels=1, model_name=\"ResNet18\"):\n",
    "    if model_name == \"ResNet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "    elif model_name == \"ResNet34\":\n",
    "        model = models.resnet34(pretrained=True)\n",
    "    elif model_name == \"ResNet50\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "    elif model_name == \"ResNet101\":\n",
    "        model = models.resnet101(pretrained=True)\n",
    "    elif model_name == \"ResNet152\":\n",
    "        model = models.resnet152(pretrained=True)\n",
    "    model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(\n",
    "        7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    fc_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(fc_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Further Vgg models\n",
    "def generate_vgg(num_classes=10, in_channels=1, model_name=\"vgg11\"):\n",
    "    if model_name == \"VGG11\":\n",
    "        model = models.vgg11(pretrained=False)\n",
    "    elif model_name == \"VGG11_bn\":\n",
    "        model = models.vgg11_bn(pretrained=True)\n",
    "    elif model_name == \"VGG13\":\n",
    "        model = models.vgg11(pretrained=False)\n",
    "    elif model_name == \"VGG13_bn\":\n",
    "        model = models.vgg11_bn(pretrained=True)\n",
    "    elif model_name == \"VGG16\":\n",
    "        model = models.vgg11(pretrained=False)\n",
    "    elif model_name == \"VGG16_bn\":\n",
    "        model = models.vgg11_bn(pretrained=True)\n",
    "    elif model_name == \"VGG19\":\n",
    "        model = models.vgg11(pretrained=False)\n",
    "    elif model_name == \"VGG19_bn\":\n",
    "        model = models.vgg11_bn(pretrained=True)\n",
    "\n",
    "    # first_conv_layer = [nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=True)]\n",
    "    # first_conv_layer.extend(list(model.features))\n",
    "    # model.features = nn.Sequential(*first_conv_layer)\n",
    "    # model.conv1 = nn.Conv2d(num_classes, 64, 7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    fc_features = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(fc_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=1):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.fp_con1 = nn.Sequential(OrderedDict([\n",
    "            ('con0', nn.Conv2d(in_channels=in_channels,\n",
    "             out_channels=32, kernel_size=3, padding=1)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "\n",
    "        self.ternary_con2 = nn.Sequential(OrderedDict([\n",
    "            # Conv Layer block 1\n",
    "            ('conv1', nn.Conv2d(in_channels=32, out_channels=64,\n",
    "             kernel_size=3, padding=1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(64)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            ('conv2', nn.Conv2d(in_channels=64, out_channels=128,\n",
    "             kernel_size=3, padding=1, bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(128)),\n",
    "            ('relu2', nn.ReLU(inplace=True)),\n",
    "            ('conv3', nn.Conv2d(in_channels=128, out_channels=128,\n",
    "             kernel_size=3, padding=1, bias=False)),\n",
    "            ('norm3', nn.BatchNorm2d(128)),\n",
    "            ('relu3', nn.ReLU(inplace=True)),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "            # nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            ('conv3', nn.Conv2d(in_channels=128, out_channels=256,\n",
    "             kernel_size=3, padding=1, bias=False)),\n",
    "            ('norm3', nn.BatchNorm2d(256)),\n",
    "            ('relu3', nn.ReLU(inplace=True)),\n",
    "            ('conv4', nn.Conv2d(in_channels=256, out_channels=256,\n",
    "             kernel_size=3, padding=1, bias=False)),\n",
    "            ('norm4', nn.BatchNorm2d(256)),\n",
    "            ('relu4', nn.ReLU(inplace=True)),\n",
    "            ('pool4', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "        ]))\n",
    "\n",
    "        self.fp_fc = nn.Linear(4096, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fp_con1(x)\n",
    "        x = self.ternary_con2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fp_fc(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09115238-42c7-460f-a753-ae83df46ee19",
   "metadata": {},
   "source": [
    "### Perfomance recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9647f-a567-4186-9e1d-f60573e1d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_types = (list, dict, str, int, float, bool, type(None))\n",
    "\n",
    "\n",
    "class PythonObjectEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, json_types):\n",
    "            return super().default(self, obj)\n",
    "        return {'_python_object': pickle.dumps(obj).decode('latin-1')}\n",
    "\n",
    "\n",
    "def as_python_object(dct):\n",
    "    if '_python_object' in dct:\n",
    "        return pickle.loads(dct['_python_object'].encode('latin-1'))\n",
    "    return dct\n",
    "\n",
    "\n",
    "class Recorder(object):\n",
    "    def __init__(self):\n",
    "        self.res_list = []\n",
    "        self.res = {'server': {'iid_accuracy': [], 'train_loss': []},\n",
    "                    'clients': {'iid_accuracy': [], 'train_loss': []}}\n",
    "\n",
    "    def load(self, filename, label):\n",
    "        \"\"\"\n",
    "        Load the result files\n",
    "        :param filename: Name of the result file\n",
    "        :param label: Label for the result file\n",
    "        \"\"\"\n",
    "        with open(filename) as json_file:\n",
    "            res = json.load(json_file, object_hook=as_python_object)\n",
    "        self.res_list.append((res, label))\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        Plot the testing accuracy and training loss on number of epochs or communication rounds\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2)\n",
    "        for i, (res, label) in enumerate(self.res_list):\n",
    "            axes[0].plot(np.array(res['server']['iid_accuracy']),\n",
    "                         label=label, alpha=1, linewidth=2)\n",
    "            axes[1].plot(np.array(res['server']['train_loss']),\n",
    "                         label=label, alpha=1, linewidth=2)\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            ax.set_xlabel('# of Epochs', size=12)\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Testing Accuracy', size=12)\n",
    "            if i == 1:\n",
    "                ax.set_ylabel('Training Loss', size=12)\n",
    "            ax.legend(prop={'size': 12})\n",
    "            ax.tick_params(axis='both', labelsize=12)\n",
    "            ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93664391-0d2c-467c-be70-5ebee3e58d0a",
   "metadata": {},
   "source": [
    "### Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83291ee-8245-4fb8-b2bf-ffb30e5a0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedClient(object):\n",
    "\n",
    "    def __init__(self, client_id, dataset_id='MNIST'):\n",
    "        \"\"\"\n",
    "        Client in the federated learning for FedD3\n",
    "        :param client_id: Id of the client\n",
    "        :param dataset_id: Dataset name for the application scenario\n",
    "        \"\"\"\n",
    "        # Metadata\n",
    "        self._id = client_id\n",
    "        self._dataset_id = dataset_id\n",
    "\n",
    "        # Following private parameters are defined by dataset.\n",
    "        self._image_length = -1\n",
    "        self._image_width = -1\n",
    "        self._image_channel = -1\n",
    "\n",
    "        if self._dataset_id == 'MNIST':\n",
    "            self._image_length = 28\n",
    "            self._image_width = 28\n",
    "            self._image_channel = 1\n",
    "\n",
    "        elif self._dataset_id == 'FashionMNIST':\n",
    "            self._image_length = 28\n",
    "            self._image_width = 28\n",
    "            self._image_channel = 1\n",
    "\n",
    "        elif self._dataset_id == 'CIFAR10':\n",
    "            self._image_length = 32\n",
    "            self._image_width = 32\n",
    "            self._image_channel = 3\n",
    "\n",
    "        elif self._dataset_id == 'CIFAR100':\n",
    "            self._image_length = 32\n",
    "            self._image_width = 32\n",
    "            self._image_channel = 3\n",
    "\n",
    "        elif self._dataset_id == 'SVHN':\n",
    "            self._image_length = 32\n",
    "            self._image_width = 32\n",
    "            self._image_channel = 3\n",
    "        else:\n",
    "            print('unexpected dataset!')\n",
    "            exit(0)\n",
    "\n",
    "        # Local dataset\n",
    "        self._train_data = None\n",
    "        self._test_data = None\n",
    "\n",
    "        # Local distilled dataset\n",
    "        self._distill_data = {'x': [], 'y': []}\n",
    "\n",
    "    def load_train(self, data):\n",
    "        \"\"\"\n",
    "        Client loads the decentralized dataset, it can be Non-IID across clients.\n",
    "        :param data: Local dataset for training.\n",
    "        \"\"\"\n",
    "        self._train_data = {}\n",
    "        self._train_data = deepcopy(data)\n",
    "\n",
    "    def load_test(self, data):\n",
    "        \"\"\"\n",
    "        Client loads the test dataset.\n",
    "        :param data: Dataset for testing.\n",
    "        \"\"\"\n",
    "        self._test_data = {}\n",
    "        self._test_data = deepcopy(data)\n",
    "\n",
    "    def kip_distill(self, k,\n",
    "                    num_train_steps=2000,\n",
    "                    seed=0,\n",
    "                    lr=4e-3,\n",
    "                    threshold=0.995,\n",
    "                    target_sample_size=5000):\n",
    "        \"\"\"\n",
    "        The client run the FedD3 with KIP-based instance.\n",
    "        More details on KIP in the paper: https://arxiv.org/abs/2011.00050\n",
    "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
    "        :param num_train_steps: Number of the decentralized distillation steps\n",
    "        :param seed: Index of the used seed\n",
    "        :param lr: Learning rate of decentralized dataset distillation\n",
    "        :param threshold: Accuracy threshold for decentralized dataset distillation, when it is exceeded, the distillation breaks out.\n",
    "        :param target_sample_size: Batch size for decentralized dataset distillation\n",
    "        :return: Distilled images from decentralized dataset in this client\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        print(\"Client %s \" % self._id +\n",
    "              \"starts distilling %d \" % len(self._train_data['y']) +\n",
    "              \"data points into %s data points\" % k)\n",
    "\n",
    "        params = distill_kip_unit(\n",
    "            np.array(self._train_data['x'].squeeze(1).permute(0, 2, 3, 1)),\n",
    "            np.array(self._train_data['y'].squeeze()), num_dd_epoch=num_train_steps, seed=seed, k=k, lr=lr,\n",
    "            threshold=threshold,\n",
    "            target_sample_size=target_sample_size, kernel_model='FC', depth=4, width=1024)\n",
    "\n",
    "        for data, data_label in zip(params['x'], params['y']):\n",
    "            data = np.asarray(data).tolist()\n",
    "            label = data_label.argmax(0)\n",
    "            label = np.asarray(label).tolist()\n",
    "            k_data_point = [label, data, k]\n",
    "            res.append(k_data_point)\n",
    "            self._distill_data['y'].append(k_data_point[0])\n",
    "            self._distill_data['x'].append(k_data_point[1])\n",
    "\n",
    "        self._distill_data['x'] = torch.tensor(\n",
    "            self._distill_data['x']).permute(0, 3, 1, 2)\n",
    "        self._distill_data['y'] = torch.tensor(self._distill_data['y'])\n",
    "\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def all_select(self):\n",
    "        \"\"\"\n",
    "        The client uploads all of the original dataset\n",
    "        :return: All of the original images\n",
    "        \"\"\"\n",
    "        return self._train_data\n",
    "\n",
    "    def herding_gmm(self, k, num_local_class, i_seed):\n",
    "        \"\"\"\n",
    "        The client run the FedD3 with coreset-based instance.\n",
    "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
    "        :param num_local_class: Number of the local classes\n",
    "        :param i_seed: Index of the used seed\n",
    "        :return: Distilled images from decentralized dataset in this client\n",
    "        \"\"\"\n",
    "        torch.manual_seed(i_seed)\n",
    "        random.seed(i_seed)\n",
    "        np.random.seed(i_seed)\n",
    "        res = []\n",
    "        self._train_data['y'] = self._train_data['y'].squeeze()\n",
    "        self._train_data['x'] = self._train_data['x'].squeeze()\n",
    "        num_datapoint = int(k / num_local_class)\n",
    "        cls_set = set()\n",
    "        for cls in self._train_data['y']:\n",
    "            cls_set.add(cls.item())\n",
    "\n",
    "        for cls in cls_set:\n",
    "            sub_data = []\n",
    "            indexes = torch.nonzero(self._train_data['y'] == cls)\n",
    "            indexes = indexes[torch.randperm(indexes.shape[0])]\n",
    "            for index in indexes:\n",
    "                sub_data.append(\n",
    "                    self._train_data['x'][index].numpy().reshape(-1).tolist())\n",
    "\n",
    "            gm = GaussianMixture(n_components=int(\n",
    "                k / num_local_class), random_state=0).fit(sub_data)\n",
    "            for x_data in gm.means_:\n",
    "                k_data_point = [cls, np.array(x_data).reshape(1, 28, 28), k]\n",
    "                res.append(k_data_point)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def dbscan(self, k, num_local_class, i_seed):\n",
    "        \"\"\"\n",
    "        The client run the FedD3 with DBSCAN-based instance.\n",
    "        :param k: Number of the local distilled images, this need to be integral times of number of local classes\n",
    "        :param num_local_class: Number of the local classes\n",
    "        :param i_seed: Index of the used seed\n",
    "        :return: Distilled images from decentralized dataset in this client\n",
    "        \"\"\"\n",
    "        torch.manual_seed(i_seed)\n",
    "        random.seed(i_seed)\n",
    "        np.random.seed(i_seed)\n",
    "        res = []\n",
    "        self._train_data['y'] = self._train_data['y'].squeeze()\n",
    "        self._train_data['x'] = self._train_data['x'].squeeze()\n",
    "        num_datapoint = int(k / num_local_class)\n",
    "        cls_set = set()\n",
    "        for cls in self._train_data['y']:\n",
    "            cls_set.add(cls.item())\n",
    "\n",
    "        for cls in cls_set:\n",
    "            sub_data = []\n",
    "            indexes = torch.nonzero(self._train_data['y'] == cls)\n",
    "            indexes = indexes[torch.randperm(indexes.shape[0])]\n",
    "            for index in indexes:\n",
    "                sub_data.append(\n",
    "                    self._train_data['x'][index].numpy().reshape(-1).tolist())\n",
    "            db = DBSCAN(eps=40.5, min_samples=2).fit(sub_data)\n",
    "            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "            core_samples_mask[db.core_sample_indices_] = True\n",
    "            labels = db.labels_\n",
    "\n",
    "            # Number of clusters in labels, ignoring noise if present.\n",
    "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(n_clusters_)\n",
    "            n_noise_ = list(labels).count(-1)\n",
    "            unique_labels = set(labels)\n",
    "            cluster_centers_ = []\n",
    "            for k in unique_labels:\n",
    "                # discard the unclustered points\n",
    "                if k == -1:\n",
    "                    continue\n",
    "                class_member_mask = (labels == k)\n",
    "                cluster = np.array(sub_data)[\n",
    "                    class_member_mask & core_samples_mask]\n",
    "                cluster_centers_.append(np.mean(cluster, axis=0))\n",
    "\n",
    "            for x_data in cluster_centers_:\n",
    "                k_data_point = [cls, np.array(x_data).reshape(3, 32, 32), k]\n",
    "                res.append(k_data_point)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def save_distilled_dataset(self, exp_dir='client_models', res_root='results'):\n",
    "        \"\"\"\n",
    "        The client saves the distilled images in corresponding directory\n",
    "        :param exp_dir: Experiment directory name\n",
    "        :param res_root: Result directory root for saving the result files\n",
    "        \"\"\"\n",
    "        agent_name = 'clients'\n",
    "        model_save_dir = os.path.join(res_root, exp_dir, agent_name)\n",
    "        if not os.path.exists(model_save_dir):\n",
    "            os.makedirs(model_save_dir)\n",
    "        torch.save(self._distill_data, os.path.join(\n",
    "            model_save_dir, self._id + '_distilled_img.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fe24e-f93b-44ea-8fc7-440f041eaa1c",
   "metadata": {},
   "source": [
    "### Server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595d2fb-2289-4e87-b3d1-2dcd6f2aacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonObjectEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, json_types):\n",
    "            return super().default(self, obj)\n",
    "        return {'_python_object': pickle.dumps(obj).decode('latin-1')}\n",
    "\n",
    "\n",
    "def as_python_object(dct):\n",
    "    if '_python_object' in dct:\n",
    "        return pickle.loads(dct['_python_object'].encode('latin-1'))\n",
    "    return dct\n",
    "\n",
    "\n",
    "class FedServer(object):\n",
    "    def __init__(self, epoch, batch_size, lr, momentum, num_workers, dataset_id='mnist', server_id='server', model_name=\"LeNet\", i_seed=0, test_on_gpu=True):\n",
    "        \"\"\"\n",
    "        Server in the federated learning for FedD3\n",
    "        :param epoch: Number of total training epochs in the server\n",
    "        :param batch_size: Batch size for the training in the server\n",
    "        :param lr: Learning rate for the training in the server\n",
    "        :param momentum: Learning momentum for the training in the server\n",
    "        :param num_workers: Number of the workers for the training in the server\n",
    "        :param dataset_id: Dataset name for the application scenario\n",
    "        :param server_id: Id of the server\n",
    "        :param model_name: Machine learning model name for the application scenario\n",
    "        :param i_seed: Index of the seed used in the experiment\n",
    "        :param test_on_gpu: Flag: 1: Run testing on GPU after every epoch, otherwise 0.\n",
    "        \"\"\"\n",
    "        data_dict = ['MNIST', 'FashionMNIST', 'CIFAR10', 'SVHN', 'CIFAR100']\n",
    "        assert dataset_id in data_dict, \"The dataset is not present\"\n",
    "\n",
    "        self.test_on_gpu = test_on_gpu\n",
    "\n",
    "        # Server Properties\n",
    "        self._id = server_id\n",
    "        self._dataset_id = dataset_id\n",
    "        self._model_name = model_name\n",
    "        self._i_seed = i_seed\n",
    "\n",
    "        # Training related parameters\n",
    "        self._epoch = epoch\n",
    "        self._batch_size = batch_size\n",
    "        self._lr = lr\n",
    "        self._momentum = momentum\n",
    "        self._num_workers = num_workers\n",
    "\n",
    "        # Global test dataset\n",
    "        self._test_data = None\n",
    "\n",
    "        # Global distilled dataset\n",
    "        self._distill_data = None\n",
    "\n",
    "        # Following private parameters are defined by dataset.\n",
    "        self.model = None\n",
    "        self._image_dim = -1\n",
    "        self._image_channel = -1\n",
    "\n",
    "        if self._dataset_id == 'MNIST':\n",
    "            self._num_class = 10\n",
    "            self._image_dim = 28\n",
    "            self._image_channel = 1\n",
    "\n",
    "        if self._dataset_id == 'FashionMNIST':\n",
    "            self._num_class = 10\n",
    "            self._image_dim = 28\n",
    "            self._image_channel = 1\n",
    "\n",
    "        elif self._dataset_id == 'SVHN':\n",
    "            self._num_class = 10\n",
    "            self._image_dim = 32\n",
    "            self._image_channel = 3\n",
    "\n",
    "        elif self._dataset_id == 'EMNIST':\n",
    "            self._num_class = 27\n",
    "            self._image_dim = 28\n",
    "            self._image_channel = 1\n",
    "\n",
    "        elif self._dataset_id == 'CIFAR10':\n",
    "            self._num_class = 10\n",
    "            self._image_dim = 32\n",
    "            self._image_channel = 3\n",
    "\n",
    "        elif self._dataset_id == 'CIFAR100':\n",
    "            self._num_class = 100\n",
    "            self._image_dim = 32\n",
    "            self._image_channel = 3\n",
    "\n",
    "        if self._model_name == \"ResNet18\":\n",
    "            self.model = generate_resnet(\n",
    "                num_classes=self._num_class, in_channels=self._image_channel, model_name=model_name)\n",
    "        elif self._model_name == \"ResNet50\":\n",
    "            self.model = generate_resnet(\n",
    "                num_classes=self._num_class, in_channels=self._image_channel, model_name=model_name)\n",
    "        elif self._model_name == \"ResNet152\":\n",
    "            self.model = generate_resnet(\n",
    "                num_classes=self._num_class, in_channels=self._image_channel, model_name=model_name)\n",
    "        elif self._model_name == \"LeNet\":\n",
    "            self.model = LeNet(self._num_class, self._image_channel)\n",
    "        elif self._model_name == \"VGG11\":\n",
    "            self.model = generate_vgg(\n",
    "                self._num_class, self._image_channel, model_name=model_name)\n",
    "        elif self._model_name == \"VGG11_bn\":\n",
    "            self.model = generate_vgg(\n",
    "                self._num_class, self._image_channel, model_name=model_name)\n",
    "        elif self._model_name == \"AlexCifarNet\":\n",
    "            self.model = AlexCifarNet()\n",
    "        elif self._model_name == \"CNN\":\n",
    "            self.model = CNN(self._num_class, self._image_channel)\n",
    "        else:\n",
    "            print('Model is not supported')\n",
    "\n",
    "        # Number of model parameter\n",
    "        model_parameters = filter(\n",
    "            lambda p: p.requires_grad, self.model.parameters())\n",
    "        self.param_len = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print('Number of model parameters of %s :' %\n",
    "              model_name, ' %d ' % self.param_len)\n",
    "        # Recording results\n",
    "        self.recorder = Recorder()\n",
    "        # Run on the GPU\n",
    "        gpu = 0\n",
    "        self._device = torch.device(\"cuda:{}\".format(\n",
    "            gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "    def load_test(self, data):\n",
    "        \"\"\"\n",
    "        Server loads the test dataset.\n",
    "        :param data: Dataset for testing.\n",
    "        \"\"\"\n",
    "        self._test_data = {}\n",
    "        self._test_data = deepcopy(data)\n",
    "\n",
    "    def load_distill(self, data):\n",
    "        \"\"\"\n",
    "        Server loads the decentralized distilled dataset.\n",
    "        :param data: Dataset for training.\n",
    "        \"\"\"\n",
    "        self._distill_data = {}\n",
    "        self._distill_data = deepcopy(data)\n",
    "\n",
    "    def train(self, exp_dir, res_root='results', i_seed=0):\n",
    "        \"\"\"\n",
    "        Server trains models on the decentralized distilled datasets from networks\n",
    "        :param exp_dir: Experiment directory name\n",
    "        :param res_root: Result directory root for saving the result files\n",
    "        :param i_seed: Index of the used seed\n",
    "        :return: Loss in the training.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(i_seed)\n",
    "        np.random.seed(i_seed)\n",
    "        state_dict_list = []\n",
    "\n",
    "        # Create the train and test loader\n",
    "        with torch.no_grad():\n",
    "\n",
    "            train_x = self._distill_data['x'].type(torch.FloatTensor).squeeze()\n",
    "            if len(train_x.shape) == 3:\n",
    "                train_x = train_x.unsqueeze(1)\n",
    "            train_y = self._distill_data['y'].type(torch.LongTensor).squeeze()\n",
    "\n",
    "            test_x = self._test_data['x'].type(torch.FloatTensor).squeeze()\n",
    "            if len(test_x.shape) == 3:\n",
    "                test_x = test_x.unsqueeze(1)\n",
    "            test_y = self._test_data['y'].type(torch.FloatTensor).squeeze()\n",
    "\n",
    "            train_loader = DataLoader(TensorDataset(\n",
    "                train_x, train_y), batch_size=self._batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(TensorDataset(\n",
    "                test_x, test_y), batch_size=self._batch_size, shuffle=True)\n",
    "\n",
    "            self.model.to(self._device)\n",
    "            # optimizer = torch.optim.SGD(self.model.parameters(), lr=self._lr, momentum=self._momentum)\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.model.parameters(), lr=self._lr, weight_decay=1e-4)\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train process\n",
    "        pbar = tqdm(range(self._epoch))\n",
    "        for epoch in pbar:\n",
    "            for step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    b_x = x.to(self._device)  # Tensor on GPU\n",
    "                    b_y = y.to(self._device)  # Tensor on GPU\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    self.model.train()\n",
    "                    output = self.model(b_x)\n",
    "                    loss = loss_func(output, b_y)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # Recording the train loss during the training\n",
    "            self.recorder.res['server']['train_loss'].append(\n",
    "                loss.data.cpu().numpy())\n",
    "\n",
    "            # Test process\n",
    "            if self.test_on_gpu:\n",
    "                accuracy_collector = 0\n",
    "                for step, (x, y) in enumerate(test_loader):\n",
    "                    with torch.no_grad():\n",
    "                        b_x = x.to(self._device)  # Tensor on GPU\n",
    "                        b_y = y.to(self._device)  # Tensor on GPU\n",
    "                        test_output = self.model(b_x)\n",
    "                        pred_y = torch.max(test_output, 1)[1].to(\n",
    "                            self._device).data.squeeze()\n",
    "                        accuracy_collector = accuracy_collector + \\\n",
    "                            sum(pred_y == b_y)\n",
    "                accuracy = accuracy_collector / self._test_data['y'].size(0)\n",
    "                self.recorder.res['server']['iid_accuracy'].append(\n",
    "                    accuracy.cpu().numpy())\n",
    "\n",
    "                pbar.set_description('Epoch: %d' % (epoch + 1) +\n",
    "                                     '| Train loss: %.4f ' % loss.data.cpu().numpy() +\n",
    "                                     '| Accuracy: %.4f' % accuracy +\n",
    "                                     '| Max Acc: %.4f' % np.max(np.array(self.recorder.res['server']['iid_accuracy'])))\n",
    "            else:\n",
    "                pbar.set_description(\n",
    "                    'Epoch: %d', (epoch + 1) + '| Train loss: %.4f ' % loss.data.cpu().numpy())\n",
    "            state_dict_list.append(self.model.state_dict())\n",
    "\n",
    "        # Save the results\n",
    "        if not os.path.exists(res_root):\n",
    "            os.makedirs(res_root)\n",
    "        if os.path.exists(os.path.join(res_root, exp_dir)):\n",
    "            os.remove(os.path.join(res_root, exp_dir))\n",
    "\n",
    "        with open(os.path.join(res_root, exp_dir), \"w\") as jsfile:\n",
    "            json.dump(self.recorder.res, jsfile, cls=PythonObjectEncoder)\n",
    "\n",
    "        return loss.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa791a-1c51-4628-891b-c2ac97b3524b",
   "metadata": {},
   "source": [
    "### Enters the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff134f-62ed-4210-883b-1682221bc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedD3(args):\n",
    "    \"\"\"\n",
    "    Main function for FedD3\n",
    "    \"\"\"\n",
    "    mode_list = [\"all_select\", \"kip_distill\", \"gmm\", \"dbscan\"]\n",
    "    assert args['client_instance'] in mode_list, \"The mode is not supported\"\n",
    "\n",
    "    dataset_list = ['MNIST', 'CIFAR10', 'FashionMNIST', 'SVHN', 'CIFAR100']\n",
    "    assert args['sys_dataset'] in dataset_list, \"The dataset is not supported\"\n",
    "\n",
    "    model_list = [\"LeNet\", 'AlexCifarNet', 'CNN',\n",
    "                  'ResNet18', 'ResNet50', \"ResNet152\"]\n",
    "    assert args['sys_model'] in model_list, \"The model is not supported\"\n",
    "\n",
    "    # Number of all distilled data points\n",
    "    num_images = int(args['client_n_dd'] * args['sys_n_client'])\n",
    "\n",
    "    # Set the experiment name with hyperparameters\n",
    "    exp_name = \"['%s','%s',%d,%d,%d,%d]\" % (\n",
    "        args['sys_dataset'], args['sys_model'], num_images, args['client_n_dd'], args['sys_n_client'], args['sys_n_local_class'])\n",
    "\n",
    "    if args['client_instance'] == \"all_select\":\n",
    "        args['sys_n_client'] = 1\n",
    "        args['sys_n_local_class'] = -1\n",
    "\n",
    "    torch.manual_seed(args['sys_i_seed'])\n",
    "    random.seed(args['sys_i_seed'])\n",
    "    np.random.seed(args['sys_i_seed'])\n",
    "\n",
    "    client_dict = {}\n",
    "    distill_dataset = {'x': [], 'y': []}\n",
    "\n",
    "    # Distribute the dataset into each client with respect to number of local classes\n",
    "    trainset_config, test_iid_data = divide_data(num_client=args['sys_n_client'],\n",
    "                                                 num_local_class=args['sys_n_local_class'],\n",
    "                                                 dataset_name=args['sys_dataset'],\n",
    "                                                 i_seed=args['sys_i_seed'])\n",
    "\n",
    "    # Initialize each client and distill the local data.\n",
    "    # (Since it is one-shot, initialization does not have to do separately)\n",
    "    for client_id in trainset_config['users']:\n",
    "        client_dict[client_id] = FedClient(\n",
    "            client_id, dataset_id=args['sys_dataset'])\n",
    "        client_dict[client_id].load_train(\n",
    "            trainset_config['user_data'][client_id])\n",
    "\n",
    "        ret_data = []\n",
    "        if args['client_instance'] == \"all_select\":\n",
    "            distill_dataset = client_dict[client_id].all_select\n",
    "        elif args['client_instance'] == \"gmm\":\n",
    "            ret_data = client_dict[client_id].herding_gmm(\n",
    "                k=args['client_n_dd'], num_local_class=args['sys_n_local_class'], i_seed=args['sys_i_seed'])\n",
    "        elif args['client_instance'] == \"dbscan\":\n",
    "            ret_data = client_dict[client_id].dbscan(\n",
    "                k=args['client_n_dd'], num_local_class=args['sys_n_local_class'], i_seed=args['sys_i_seed'])\n",
    "        elif args['client_instance'] == \"kip_distill\":\n",
    "            ret_data = client_dict[client_id].kip_distill(\n",
    "                args['client_n_dd'],\n",
    "                num_train_steps=args['client_instance_max_n_epoch'],\n",
    "                seed=args['sys_i_seed'],\n",
    "                lr=args['client_instance_lr'],\n",
    "                threshold=args['client_instance_threshold'],\n",
    "                target_sample_size=args['client_instance_bs'])\n",
    "        for k_data_point in ret_data:\n",
    "            distill_dataset['y'].append(k_data_point[0])\n",
    "            distill_dataset['x'].append(k_data_point[1])\n",
    "\n",
    "    if args['client_instance'] == \"all_select\":\n",
    "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
    "        distill_dataset['x'] = distill_dataset['x'].squeeze()\n",
    "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
    "    elif args['client_instance'] == \"gmm\":\n",
    "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
    "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
    "    elif args['client_instance'] == \"dbscan\":\n",
    "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
    "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
    "    elif args['client_instance'] == \"kip_distill\":\n",
    "        distill_dataset['x'] = torch.tensor(distill_dataset['x'])\n",
    "        distill_dataset['x'] = distill_dataset['x'].permute(0, 3, 1, 2)\n",
    "        distill_dataset['y'] = torch.tensor(distill_dataset['y'])\n",
    "\n",
    "    # Initialize the server in federated learning\n",
    "    server = FedServer(epoch=args['server_n_epoch'],\n",
    "                       batch_size=args['server_bs'],\n",
    "                       lr=args['server_lr'], momentum=args['server_momentum'],\n",
    "                       num_workers=args['server_n_worker'],\n",
    "                       server_id='server',\n",
    "                       dataset_id=args['sys_dataset'],\n",
    "                       model_name=args['sys_model'],\n",
    "                       i_seed=args['sys_i_seed'],\n",
    "                       test_on_gpu=True)\n",
    "\n",
    "    # Server loads non-iid test dataset\n",
    "    server.load_test(test_iid_data)\n",
    "    # Server collects the decentralized distilled dataset from clients\n",
    "    server.load_distill(distill_dataset)\n",
    "    print('Server gets %d images' % len(distill_dataset['y']))\n",
    "    print('Server starts experiment with  '\n",
    "          'i_seed=%d' % args['sys_i_seed'],\n",
    "          '| epoch=%d' % args['server_n_epoch'],\n",
    "          '| batch_size=%d' % args['server_bs'],\n",
    "          '| lr=%.4f' % args['server_lr'],\n",
    "          '| momentum=%.4f' % args['server_momentum'],\n",
    "          '| num_workers=%d' % args['server_n_worker'],\n",
    "          '| dataset_id=%s' % args['sys_dataset'],\n",
    "          '| model_name=%s' % args['sys_model'])\n",
    "    # Server trains models\n",
    "    server.train(exp_name, args['sys_res_root'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371babc-3542-4fe9-a9f4-77001d9d5316",
   "metadata": {},
   "source": [
    "### Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfacc4-9095-406d-8da2-ded9a3b6c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_eval(sys_res_root):\n",
    "    \"\"\"\n",
    "    Main function for result evaluation\n",
    "    \"\"\"\n",
    "    recorder = Recorder()\n",
    "\n",
    "    res_files = [f for f in os.listdir(sys_res_root)]\n",
    "    for f in res_files:\n",
    "        recorder.load(os.path.join(sys_res_root, f), label=f)\n",
    "    recorder.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e31b28-5ee9-401a-93ed-ff54ffe5f233",
   "metadata": {},
   "source": [
    "### Run FedD3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb65aab-4a2f-4d24-a027-f3f83e4c67fb",
   "metadata": {},
   "source": [
    "##### Explanations of Arguments\n",
    "\n",
    "- `sys-n_client`: Number of clients\n",
    "- `sys-n_local_class`: Number of classes in each client\n",
    "- `sys-dataset`: Dataset name (one of \"MNIST\", \"CIFAR-10\", \"FashionMnist\", \"SVHN\", or \"CIFAR100\")\n",
    "- `sys-model`: Model name (e.g., \"LeNet\" for MNIST, \"AlexCifarNet\" for CIFAR-10, \"CNN\" for CIFAR-100)\n",
    "- `sys-i_seed`: Seed used in experiments\n",
    "- `sys-res_root`: Root directory of results\n",
    "  \n",
    "- `server-n_epoch`: Number of server training epochs\n",
    "- `server-bs`: Server batch size\n",
    "- `server-lr`: Server learning rate\n",
    "- `server-momentum`: Server momentum\n",
    "- `server-n_worker`: Number of server workers\n",
    "\n",
    "- `client-instance`: Instance used in clients (\"kip_distill\", \"herding\", etc.)\n",
    "- `client-n_dd`: Number of distilled images in clients\n",
    "- `client-instance_lr`: Client learning rate\n",
    "- `client-instance_bs`: Client batch size\n",
    "- `client-instance_max_n_epoch`: Maximum number of client epochs\n",
    "- `client-instance_threshold`: Dataset distillation accuracy threshold for clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093a339-9b2b-4783-ab1a-2b5b42f47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"sys_n_client\": 10,\n",
    "    \"sys_n_local_class\": 10,\n",
    "    \"sys_dataset\": \"MNIST\",\n",
    "    \"sys_model\": \"LeNet\",\n",
    "    \"sys_i_seed\": 0,\n",
    "    \"sys_res_root\": \"results\",\n",
    "    \"server_n_epoch\": 20,\n",
    "    \"server_bs\": 50,\n",
    "    \"server_lr\": 0.001,\n",
    "    \"server_momentum\": 0.9,\n",
    "    \"server_n_worker\": 1,\n",
    "    \"client_instance\": \"kip_distill\",\n",
    "    \"client_n_dd\": 10,\n",
    "    \"client_instance_lr\": 0.004,\n",
    "    \"client_instance_bs\": 10,\n",
    "    \"client_instance_max_n_epoch\": 3000,\n",
    "    \"client_instance_threshold\": 0.99,\n",
    "}\n",
    "\n",
    "fedD3(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67d077-d4dd-4068-b4a2-e850ee372e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eval(args['sys_res_root'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
